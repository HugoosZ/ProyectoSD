networks:
  trafico-network:
    driver: bridge

volumes:
  db-data:
  processing-results:

services:

  waze-processing:
    build: ./processing
    container_name: waze-processing
    volumes: #local:docker
      - ./processing:/app  #lo de processing se monta en /app
      - ./hadoop-data:/hadoop-data #Lo de hadoop-data (datanode, namenode) se monta en /hadoop-data
      - ./processing/results:/processing # processing results se monta en /processing (no existe results, entonces acá se guarden los resultados del contenedor)
    depends_on:
      - hadoop-namenode
      - hadoop-datanode
    networks:
      - trafico-network

  hadoop-namenode: # Nodo maestro encargado de almacenar las metadata, de la biblioteca(datanode) es como el catologo que sabe todo lo que hay en la biblioteca
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-namenode
    environment:
      - CLUSTER_NAME=test # Nombre del cluster (Probablemente no se use)
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:9000 #Define que se usará hdfs, donde ademas le dice a hadoop que el fs está en el namenode, escuchando al puerto 9000
      - CORE_CONF_hadoop_http_staticuser_user=root # Se define que la interfaz web de hadoop se ejecuta como el usuario root sin login
      - CORE_CONF_hadoop_proxyuser_hue_hosts=* #Permite que un “usuario proxy” llamado hue (una interfaz web para Hadoop) se conecte desde cualquier host (*). (Problamente no se usa)
      - CORE_CONF_hadoop_proxyuser_hue_groups=* #Igual que la anterior, pero permite que el usuario hue actúe en nombre de cualquier grupo (*). (Problamente no se usa)
      - CORE_CONF_io_compression_codecs=org.apache.hadoop.io.compress.SnappyCodec # Configura los códecs de compresión que usará Hadoop.
      # Donde SnappyCodec es un códec de compresión rápido y eficiente de Google.
    ports:
      - "50070:50070" #Interfaz web de namenode
      - "9000:9000" # Comunicacion HDFS 
    volumes:
      - ./hadoop-data/namenode:/hadoop/dfs/name # Catalogo de la biblioteca
    networks:
      - trafico-network

  hadoop-datanode: #Los nodos esclavos encargados de almacenar fisicamente los datos (128mb por defecto) que se reparten en n datanodes
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: hadoop-datanode
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:9000
      - CORE_CONF_hadoop_http_staticuser_user=root
      - CORE_CONF_hadoop_proxyuser_hue_hosts=*
      - CORE_CONF_hadoop_proxyuser_hue_groups=*
      - CORE_CONF_io_compression_codecs=org.apache.hadoop.io.compress.SnappyCodec
      # Todo igual que en namenode, donde gracias a las imagenes que estan diseñadas para generar automaticamente los archivos de configuracion
      # Las variables de en el entorno se convierten en archivos de configuracion de hadoop, donde por ejemplo CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:9000 la imagen transforma esto en el archivo core-site.xml
      # osea que podria borrar los archivos con/core-site.xml y hdfs-site.xml y seguiria funcionando, ya que las variables de entorno se convierten en archivos de configuracion de hadoop
    volumes:
      - ./hadoop-data/datanode:/hadoop/dfs/data #Donde se almacenan los datos fisicos
    depends_on:
      - hadoop-namenode # Espera a que el nodo maestro este listo
    networks:
      - trafico-network

    #Flujo de lanzamiento de hadoop:
    # 1. Arranca el namenode y se conecta al puerto 9000
    # 2. Arranca el datanode y se conecta al namenode y empieza a reportar salud y disponibilidad de bloques.
    # 3. Arranca waze-processing y se conecta mediante el puerto 9000 al namenode y de acá se ejecutan los comandos
